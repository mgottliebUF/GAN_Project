import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.io.gfile import glob
import os
import matplotlib.pyplot as plt
import tensorflow.keras as keras
import tensorflow.keras.layers as layers
from sklearn.decomposition import PCA
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import shutil
import PIL

for dirname, _, filenames in os.walk('/kaggle/input'):
    print(dirname, len(os.listdir(dirname)))
AUTOTUNE = tf.data.experimental.AUTOTUNE

if len(tf.config.list_physical_devices()) >= 3:
    strategy = tf.distribute.MirroredStrategy()
    print("Number of devices", strategy.num_replicas_in_sync)    
else: 
    strategy = tf.distribute.get_strategy()

Monet_files = glob(str('/kaggle/input/gan-getting-started/monet_tfrec/*.tfrec'))
print('Monet TFRecord Files:', len(Monet_files))
Photo_files = glob(str('/kaggle/input/gan-getting-started/photo_tfrec/*.tfrec'))
print('Photo TFRecord Files:', len(Photo_files))

raw_dataset = tf.data.TFRecordDataset(Monet_files[0])
for raw_record in raw_dataset.take(1):
    example = tf.train.Example()
    example.ParseFromString(raw_record.numpy())
    Monet_features = [i for i in example.features.feature]

raw_dataset = tf.data.TFRecordDataset(Photo_files[0])
for raw_record in raw_dataset.take(1):
    example = tf.train.Example()
    example.ParseFromString(raw_record.numpy())
    Photo_features = [i for i in example.features.feature]

print('Monet tfrecord Features:', Monet_features)
print('Photo tfrecord Features:', Photo_features)

IMAGE_SIZE = [256, 256]

def decode_image(image):
    image = tf.image.decode_jpeg(image, channels=3)
    image = tf.image.convert_image_dtype(image, tf.float32)
    image = tf.reshape(image, [*IMAGE_SIZE, 3])
    return image

def read_tfrecord(example):
    tfrecord_format = {
        "image_name": tf.io.FixedLenFeature([], tf.string),
        "image": tf.io.FixedLenFeature([], tf.string),
        "target": tf.io.FixedLenFeature([], tf.string)
    }
    example = tf.io.parse_single_example(example, tfrecord_format)
    image = decode_image(example['image'])
    return image

def load_dataset(filenames, labeled=True, ordered=False, repeat = False):
    dataset = tf.data.TFRecordDataset(filenames)
    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)
    if repeat:
        dataset = dataset.repeat(count = 20)
    dataset = dataset.shuffle(1000)
    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return dataset

batch_size = 15
photo_ds = load_dataset(Photo_files, labeled = True).batch(15)
monet_ds = load_dataset(Monet_files, labeled = True, repeat = True).batch(15)
example_monet = next(iter(monet_ds))
example_photo = next(iter(photo_ds))

fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(15, 6))
fig.suptitle('Image Categories', fontsize=16)

for i in range(0,5):
    ax = axes[0, i]
    ax.imshow(example_monet[i])
    ax.axis('off')

for i in range(0,5):
    ax = axes[1, i]
    ax.imshow(example_photo[i])
    ax.axis('off')

axes[0, 2].set_title('Monet', size='large', loc='center')
axes[1, 2].set_title('Photo', size='large', loc='center')
plt.tight_layout()
plt.show()

class Downsample(keras.layers.Layer):
    def __init__(self,filters, kernel_size = (2,2), strides=(2, 2), padding='same', activation = 'leaky_relu', **kwargs):
        super(Downsample, self).__init__(**kwargs)
        self.initializer = tf.random_normal_initializer(0., 0.02)
        self.gamma_init = keras.initializers.RandomNormal(mean=0.0, stddev=0.02)
        self.conv = layers.Conv2D(filters, kernel_size = kernel_size, 
                                  strides = strides, padding = padding, kernel_initializer = self.initializer)
        self.bn = layers.BatchNormalization()
        self.activation = layers.Activation(activation = activation)
        
    def call(self, inputs,training = False):
        x = self.conv(inputs)
        x = self.bn(x, training = training)
        x = self.activation(x)
        return x
    
    def get_config(self):
        config = super(Downsample, self).get_config()
        config.update({
            'filters': self.conv.filters,
            'kernel_size': self.conv.kernel_size,
            'strides': self.conv.strides,
            'padding': self.conv.padding,
            'activation': self.activation.activation,
        })
        return config

def apply_pca_and_visualize(convolved_images):
    shape = convolved_images.shape
    normalized_image = convolved_images / 255.0
    reshaped_image = tf.reshape(normalized_image, (-1, shape[-1]))
    reshaped_array = reshaped_image.numpy()
    pca = PCA(n_components=1)
    pca_result = pca.fit_transform(reshaped_array)
    pca_image_reshaped = pca_result.reshape(shape[0], shape[1], 1)
    return pca_image_reshaped

filters = [32,64,128,256]
convolutions = []
convolutions.append(example_monet)
for count,element in enumerate(filters):
    Block = Downsample(element)
    convolutions.append(Block(convolutions[count]))

fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15, 3))
fig.suptitle('Downsampling', fontsize=16)
batch_number = 3

ax = axes[0]
ax.imshow(convolutions[0][batch_number])
axes[0].set_title('Original Monet', size='large', loc='center')

ax = axes[1]
ax.imshow(apply_pca_and_visualize(convolutions[0][batch_number])*255.0, cmap = 'winter')
axes[1].set_title('PCA', size='large', loc='center')

for i in range(1, len(convolutions)):
    ax = axes[i+1]
    ax.imshow(apply_pca_and_visualize(convolutions[i][batch_number])*255.0, cmap = 'winter')
    axes[i+1].set_title(f'Downsample {convolutions[i].shape[-1]} filters', size='medium', loc='center')

plt.show()

class ResidualBlock(keras.layers.Layer):
    def __init__(self, filters = 512, kernel_size=(3, 3), strides=(1, 1), padding='same', activation = 'leaky_relu', **kwargs):
        super(ResidualBlock, self).__init__(**kwargs)
        self.conv1 = layers.Conv2D(filters, kernel_size, strides, padding)
        self.bn1 = layers.BatchNormalization()
        self.activation = layers.ReLU()
        self.conv2 = layers.Conv2D(filters, kernel_size, strides, padding)
        self.bn2 = layers.BatchNormalization()

    def call(self, inputs, training=False):
        x = self.conv1(inputs)
        x = self.bn1(x, training=training)
        x = self.activation(x)
        x = self.conv2(x)
        x = self.bn2(x)
        return layers.Add()([inputs, x])

class Upsample(keras.layers.Layer):
    def __init__(self,filters, kernel_size = (2,2), strides=(2, 2), padding='same', activation = 'leaky_relu', dropout = 0.2,**kwargs):
        super(Upsample, self).__init__(**kwargs)
        self.initializer = tf.random_normal_initializer(0., 0.02)
        self.conv = layers.Conv2DTranspose(filters, kernel_size = kernel_size, 
                                           strides = strides, padding = padding, kernel_initializer = self.initializer)
        self.bn = layers.BatchNormalization()
        self.dropout = layers.Dropout(dropout)
        self.activation = layers.Activation(activation = activation)
    
    def call(self, inputs,training = False, dropout = False):
        x = self.conv(inputs)
        x = self.bn(x, training = training)
        if dropout:
            x = self.dropout(x)
        x = self.activation(x)
        return x
    
    def get_config(self):
        config = super(Upsample, self).get_config()
        config.update({
            'filters': self.conv.filters,
            'kernel_size': self.conv.kernel_size,
            'strides': self.conv.strides,
            'padding': self.conv.padding,
            'activation': self.activation.activation,
        })
        return config

upsample_filters = [512,256,128,3]
upsample_test = []
upsample_test.append(convolutions[-1])
for count,element in enumerate(upsample_filters):
    upsample_block = Upsample(element)
    upsample_test.append(upsample_block(upsample_test[count], dropout = True, training = False))
    
fig, axes = plt.subplots(nrows=1, ncols=6, figsize=(15, 3))
fig.suptitle('Upsampling', fontsize=16)
batch_number = 3
 
for i in range(0, len(upsample_test)-1):
    ax = axes[i]
    ax.imshow(apply_pca_and_visualize(upsample_test[i][batch_number])*255.0, cmap = 'winter')
    axes[i].set_title(f'Upsample {upsample_test[i].shape[-1]} filters', size='medium', loc='center')

ax = axes[4]
ax.imshow(apply_pca_and_visualize(upsample_test[-1][batch_number])*255.0, cmap = 'winter')
axes[4].set_title('PCA', size='large', loc='center')

ax = axes[5]
ax.imshow(upsample_test[-1][batch_number]*255.0)
axes[5].set_title('Original', size='large', loc='center')

plt.show()

class Generator(keras.Model):
    def __init__(self, name = 'Generator',**kwargs):
        super(Generator, self).__init__(name = name, **kwargs)
        self.downsample1 = Downsample(64, name = 'Donwsample_same', strides = (1,1), kernel_size = (5,5))
        self.downsample2 = Downsample(128, name = 'Donwsample_128')
        self.downsample3 = Downsample(128, name = 'Donwsample_64')
        self.downsample4 = Downsample(256, name = 'Donwsample_32')
        self.downsample5 = Downsample(512, name = 'Donwsample_16')
        self.downsample6 = Downsample(512, name = 'Donwsample_8')
        self.downsample7 = Downsample(512, name = 'Donwsample_4')
        self.residual1 = ResidualBlock()
        self.residual2 = ResidualBlock()
        self.residual3 = ResidualBlock()
        self.upsample1 = Upsample(512, name = 'Upsample_8')
        self.upsample2 = Upsample(512, name = 'Upsample_16')
        self.upsample3 = Upsample(256,name = 'Upsample_32')
        self.upsample4 = Upsample(128, name = 'Upsample_64')
        self.upsample5 = Upsample(128, name = 'Upsample_128')
        self.upsample6 = Upsample(64, name = 'Upsample_256')
        self.final_upsample = Upsample(3, activation = 'tanh', name = 'Output_layer', strides = (1,1))
        
    def call(self, inputs, training = False):
        d1 = self.downsample1(inputs, training = training)
        d2 = self.downsample2(d1, training = training)
        d3 = self.downsample3(d2, training = training)
        d4 = self.downsample4(d3, training = training)
        d5 = self.downsample5(d4, training = training)
        d6 = self.downsample6(d5, training = training)
        d7 = self.downsample7(d6, training = training)
        
        r1 = self.residual1(d7, training = training)
        r2 = self.residual2(r1, training = training)
        r3 = self.residual3(r2, training = training)

        u1 = self.upsample1(r3, training = training)
        u1_concat = tf.concat([u1, d6], axis=-1)
        u2 = self.upsample2(u1_concat, training = training)
        u2_concat = tf.concat([u2, d5], axis=-1)
        u3 = self.upsample3(u2_concat, training = training)
        u3_concat = tf.concat([u3, d4], axis=-1)
        u4 = self.upsample4(u3_concat, training = training)
        u4_concat = tf.concat([u4, d3], axis=-1)
        u5 = self.upsample5(u4_concat, training = training)
        u5_concat = tf.concat([u5, d2], axis=-1)
        u6 = self.upsample6(u5_concat, training = training)
        u6_concat = tf.concat([u6, d1], axis=-1)
        x = self.final_upsample(u6_concat, training = training)
        return x

g = Generator()
g.compile(optimizer = 'adam', loss = 'mse')
x = g(example_photo, training = True)
g.summary()

fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 6))
fig.suptitle('Monet Generator', fontsize=16)
ax = axes[0]
ax.imshow(example_photo[2])
axes[0].set_title('Photo', size='large', loc='center')
ax = axes[1]
ax.imshow(x[2])
axes[1].set_title('Photo as a Monet', size='large', loc='center')
plt.show()

class Discriminator(keras.Model):
    def __init__(self, name = 'Discriminator', dense = 64, activation = 'leaky_relu', **kwargs):
        super(Discriminator, self).__init__(name = name, **kwargs)
        self.initializer = tf.random_normal_initializer(0., 0.02)
        self.downsample1 = Downsample(64, name = 'Downsample_128')
        self.downsample2 = Downsample(128, name = 'Downsample_64')
        self.downsample3 = Downsample(256, name = 'Downsample_32')
        self.downsample4 = Downsample(256, name = 'Downsample_16')
        self.zeropad = layers.ZeroPadding2D(name = 'Zero_Padding')
        self.downsample5 = Downsample(512, strides = (1,1), kernel_size = (2,2), name = 'Downsample_stride_1')
        self.flatten = layers.Flatten(name = 'Flatten_layer')
        self.dense = layers.Dense(dense, name = f'Hiden_layer_{dense}')
        self.dropout = layers.Dropout(0.2, name = 'Dropout')
        self.activation = layers.Activation(activation,name =  f'{activation}')
        self.last = layers.Dense(1, activation = 'sigmoid')
        
    def call(self,inputs, training = False):
        x = self.downsample1(inputs, training = training)
        x = self.downsample2(x, training = training)
        x = self.downsample3(x, training = training)
        x = self.downsample4(x, training = training)
        x = self.zeropad(x)
        x = self.downsample5(x, training =training)
        x = self.flatten(x)
        x = self.dense(x)
        x = self.dropout(x)
        x = self.activation(x)
        x = self.last(x)
        return x

def generator_loss(disc_output):
    return keras.losses.BinaryCrossentropy(from_logits=False)(tf.ones_like(disc_output), disc_output)

def discriminator_loss(real_output, fake_output):
    real_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)(tf.ones_like(real_output), real_output)
    fake_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)(tf.zeros_like(fake_output), fake_output)
    return real_loss + fake_loss

def cycle_loss(real_image, cycled_image, lambda_cycle=10):
    return lambda_cycle * tf.reduce_mean(tf.abs(real_image - cycled_image))

def identity_loss(real_image, same_image, lambda_identity=5):
    return lambda_identity * tf.reduce_mean(tf.abs(real_image - same_image))

class CycleGAN(keras.Model):
    def __init__(self, name = 'CycleGAN', lambda_cycle = 10, lambda_identity = 5):
        super(CycleGAN,self).__init__(name = name)
        self.monet_generator_ = Generator(name = 'Monet_Generator')
        self.monet_discriminator_ = Discriminator(name = 'Monet_Discriminator')
        self.photo_generator_ = Generator(name = 'Photo_Generator')
        self.photo_discriminator_ = Discriminator(name = 'Photo_Discriminator')
        self.lambda_cycle = lambda_cycle
        self.lambda_identity = lambda_identity

    def compile(self, m_gen_optimizer, p_gen_optimizer, m_disc_optimizer, p_disc_optimizer,  **kwargs):
        super(CycleGAN, self).compile(**kwargs)
        self.m_gen_optimizer = m_gen_optimizer
        self.p_gen_optimizer = p_gen_optimizer
        self.m_disc_optimizer = m_disc_optimizer
        self.p_disc_optimizer = p_disc_optimizer
        self.bce_ = tf.keras.losses.BinaryCrossentropy(from_logits = False)
        
    def generator_loss_(self, disc_output):
        return self.bce_(tf.ones_like(disc_output), disc_output)
    
    def discriminator_loss_(self, real_output, fake_output):
        real_loss = self.bce_(tf.ones_like(real_output), real_output)
        fake_loss = self.bce_(tf.zeros_like(fake_output), fake_output)
        return real_loss + fake_loss
    
    def cycle_loss_(self,real_image, cycled_image):
        return self.lambda_cycle * tf.reduce_mean(tf.abs(real_image - cycled_image))
    
    def identity_loss_(self, real_image, same_image):
        return self.lambda_identity * tf.reduce_mean(tf.abs(real_image - same_image))
    
    def train_step(self, batch_data):
        real_monet, real_photo = batch_data
        with tf.GradientTape(persistent = True) as tape:
            fake_monet = self.monet_generator_(real_photo, training = True)
            cycled_photo =self.photo_generator_(fake_monet, training = True)
            fake_photo = self.photo_generator_(real_monet, training = True)
            cycled_monet = self.monet_generator_(fake_photo, training = True)
            same_monet = self.monet_generator_(real_monet, training = True)
            same_photo = self.photo_generator_(real_photo, training = True)
            disc_real_monet = self.monet_discriminator_(real_monet, training = True)
            disc_fake_monet = self.monet_discriminator_(fake_monet, training = True)
            disc_real_photo = self.photo_discriminator_(real_photo, training = True)
            disc_fake_photo = self.photo_discriminator_(fake_photo, training = True)
            gen_monet_loss = self.generator_loss_(disc_fake_monet)
            gen_photo_loss = self.generator_loss_(disc_fake_photo)
            disc_monet_loss = self.discriminator_loss_(disc_real_monet, disc_fake_monet)
            disc_photo_loss = self.discriminator_loss_(disc_real_photo, disc_fake_photo)
            cycle_loss = self.cycle_loss_(real_monet, cycled_monet) + self.cycle_loss_(real_photo, cycled_photo)
            identity_loss = self.identity_loss_(real_monet,same_monet) + self.identity_loss_(real_photo, same_photo)
            total_gen_monet_loss = gen_monet_loss + cycle_loss + identity_loss
            total_gen_photo_loss = gen_photo_loss + cycle_loss + identity_loss
            
        monet_generator_gradients = tape.gradient(total_gen_monet_loss, self.monet_generator_.trainable_variables)
        photo_generator_gradients = tape.gradient(total_gen_photo_loss, self.photo_generator_.trainable_variables)
        monet_discriminator_gradients = tape.gradient(disc_monet_loss, self.monet_discriminator_.trainable_variables)
        photo_discriminator_gradients = tape.gradient(disc_photo_loss, self.photo_discriminator_.trainable_variables)
        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients,self.monet_generator_.trainable_variables))
        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients,self.photo_generator_.trainable_variables))
        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients,self.monet_discriminator_.trainable_variables))
        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients,self.photo_discriminator_.trainable_variables))

        return {
            "monet_gen_loss": total_gen_monet_loss,
            "photo_gen_loss": total_gen_photo_loss,
            "monet_disc_loss": disc_monet_loss,
            "photo_disc_loss": disc_photo_loss}

class callbacks(keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs={}):
        randomint = np.random.randint(0,15,1)[0]
        if epoch != 0:
            fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(15, 4))
            fig.suptitle(f'Generator evolution epoch #{epoch}', fontsize=16)
            ax = axes[0]
            ax.imshow(example_photo[randomint])
            axes[0].set_title('Original Photo', size='large', loc='center')
            ax.axis('off')
            ax = axes[1]
            ax.imshow(cycle_gan.monet_generator_(example_photo)[randomint])
            axes[1].set_title('Photo to Monet', size='large', loc='center')
            ax.axis('off')
            ax = axes[2]
            ax.imshow(example_monet[randomint])
            axes[2].set_title('Original Monet', size='large', loc='center')
            ax.axis('off')
            ax = axes[3]
            ax.imshow(cycle_gan.photo_generator_(example_monet)[randomint])
            axes[3].set_title('Monet to photo', size='large', loc='center')
            ax.axis('off')
            plt.show()
        if epoch == 0:
            fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(15, 4))
            fig.suptitle(f'Starting point', fontsize=16)
            ax = axes[0]
            ax.imshow(example_photo[randomint])
            axes[0].set_title('Original Photo', size='large', loc='center')
            ax.axis('off')
            ax = axes[1]
            ax.imshow(cycle_gan.monet_generator_(example_photo)[randomint])
            axes[1].set_title('Photo to Monet', size='large', loc='center')
            ax.axis('off')
            ax = axes[2]
            ax.imshow(example_monet[randomint])
            axes[2].set_title('Original Monet', size='large', loc='center')
            ax.axis('off')
            ax = axes[3]
            ax.imshow(cycle_gan.photo_generator_(example_monet)[randomint])
            axes[3].set_title('Monet to photo', size='large', loc='center')
            ax.axis('off')
            plt.show()

callback = callbacks()
initial_learning_rate = 0.001
decay_steps = 100000
decay_rate = 0.96

with strategy.scope():
    monet_gen_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    photo_gen_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    monet_disc_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    photo_disc_lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(
        initial_learning_rate, decay_steps, decay_rate, staircase=True)
    m_gen_opt = tf.keras.optimizers.Adam(learning_rate = monet_gen_lr_schedule, beta_1=0.5)
    p_gen_opt = tf.keras.optimizers.Adam(learning_rate = photo_gen_lr_schedule, beta_1=0.5)
    m_disc_opt = tf.keras.optimizers.Adam(learning_rate = monet_disc_lr_schedule, beta_1=0.5)
    p_disc_opt = tf.keras.optimizers.Adam(learning_rate = photo_disc_lr_schedule, beta_1=0.5)

with strategy.scope():
    m_gen_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    p_gen_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    m_disc_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
    p_disc_opt = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

with strategy.scope():
    cycle_gan = CycleGAN()
    cycle_gan.compile(m_gen_opt, p_gen_opt, m_disc_opt, p_disc_opt)
cycle_gan.summary()

cycle_gan.fit(tf.data.Dataset.zip((monet_ds, photo_ds)), epochs=5, verbose = 1, callbacks = callback)

Dog_files = glob(str('/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Dog/*.jpg'))[0:5000]
print('Dog_files:', len(Dog_files))
Cat_files = glob(str('/kaggle/input/microsoft-catsvsdogs-dataset/PetImages/Cat/*.jpg'))[0:5000]
print('Cat_files:', len(Cat_files))
submission_images = Dog_files + Cat_files
submission_images.pop(3389)
submission_images.pop(3970)
submission_images.pop(5222)

def is_valid_image(image):
    return tf.shape(image).shape[-1] ==  3

def decode_image_2(image):
    try:
        image = tf.image.decode_image(image, channels=3,expand_animations=False)
        image.set_shape([None, None, 3])
        image = tf.image.convert_image_dtype(image, tf.float32)
        if is_valid_image(image):
            image =  tf.image.resize_with_crop_or_pad(image, 256, 256)
            image = tf.reshape(image, [*IMAGE_SIZE, 3])
            return image
        else:
            return tf.zeros([256, 256, 3], dtype=tf.float32)
    except Exception as e:
        print(f"Error decoding image: {e}")
        return tf.zeros([256, 256, 3], dtype=tf.float32)

def read_and_decode_image(filename):
    try:
        image = tf.io.read_file(filename)
        if tf.size(image) > 0: 
            return decode_image_2(image)
        else:
            return tf.zeros([256, 256, 3], dtype=tf.float32)
    except Exception as e:
        print(f"Error reading image file: {e}")
        return tf.zeros([256, 256, 3], dtype=tf.float32) 
    
def load_sub_dataset(filenames, labeled=True, ordered=False, repeat = False):
    dataset = tf.data.Dataset.from_tensor_slices(filenames)
    dataset = dataset.map(read_and_decode_image, num_parallel_calls=AUTOTUNE)
    return dataset

Dogs = load_sub_dataset(Dog_files).batch(15)
example_dog = next(iter(Dogs))
Cats = load_sub_dataset(Cat_files).batch(15)
example_cat = next(iter(Cats))
submission_dataset = load_sub_dataset(submission_images).batch(1)

fig, axes = plt.subplots(nrows=1, ncols = 4, figsize=(15, 4))
fig.suptitle('Dogs and Cats', fontsize=16)

ax = axes[0]
ax.imshow(example_dog[0])
axes[0].set_title('Dog or Cat', size='large', loc='center')
ax.axis('off')

ax = axes[1]
ax.imshow(cycle_gan.monet_generator_(example_dog)[0])
axes[1].set_title('Monetized Dog dd', size='large', loc='center')
ax.axis('off')

ax = axes[2]
ax.imshow(example_cat[0])
axes[2].set_title('Cat', size='large', loc='center')
ax.axis('off')

ax = axes[3]
ax.imshow(cycle_gan.monet_generator_(example_cat)[0])
axes[3].set_title('Monetized Cat dd', size='large', loc='center')
ax.axis('off')

plt.show()

try:
    shutil.rmtree("/kaggle/working/images")
except:
    pass
os.mkdir("/kaggle/working/images")
for count,element in enumerate(submission_dataset):
    prediction = cycle_gan.monet_generator_(element, training = False)[0]
    image = tf.image.convert_image_dtype(prediction, tf.uint8)
    image = tf.image.encode_jpeg(image)
    tf.io.write_file(f'/kaggle/working/images/{count}.jpg', image)
shutil.make_archive("/kaggle/working/images", 'zip', "/kaggle/working/images")
print('zip file done')
shutil.rmtree("/kaggle/working/images")
